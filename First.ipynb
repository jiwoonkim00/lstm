{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c309dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Keys set in environment (this kernel).\n",
      "MODEL= gemini-1.5-flash | PROVIDER_PLACES= kakao\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 🔐 여기에 너의 실제 Gemini API 키를 넣어줘 (예: AIza... 형태)\n",
    "GEMINI_API_KEY     = \"AIzaSyBQZf_zvXm4lLU0FuWmCUyzIb58V8MtTP0\"\n",
    "# Kakao/OpenWeather는 원할 때만(없으면 빈 문자열/모의 동작)\n",
    "KAKAO_REST_API_KEY = \"a09b700883a323951739abd49bce2a7a\"\n",
    "OPENWEATHER_API_KEY = \"6f0a079ee5a654b20ca8705d2ebd974a\"\n",
    "\n",
    "# 장소 제공자: \"mock\"(기본) 또는 \"kakao\"\n",
    "PLACES_PROVIDER = \"kakao\"  # kakao 쓰려면 \"kakao\"\n",
    "\n",
    "# 모델은 무료 쿼터 넉넉한 'flash' 추천. 더 성능 원하면 \"gemini-1.5-pro\"\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# ▶ OS 환경 변수 주입\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "os.environ[\"GEMINI_MODEL\"] = GEMINI_MODEL\n",
    "os.environ[\"PROVIDER_PLACES\"] = PLACES_PROVIDER\n",
    "os.environ[\"KAKAO_REST_API_KEY\"] = KAKAO_REST_API_KEY\n",
    "os.environ[\"OPENWEATHER_API_KEY\"] = OPENWEATHER_API_KEY\n",
    "\n",
    "print(\"✅ Keys set in environment (this kernel).\")\n",
    "print(\"MODEL=\", os.getenv(\"GEMINI_MODEL\"), \"| PROVIDER_PLACES=\", os.getenv(\"PROVIDER_PLACES\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ed2fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install -U fastapi uvicorn google-generativeai httpx pydantic nest_asyncio requests\n",
      "✅ dependencies installed\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "def sh(cmd):\n",
    "    print(\">\", cmd)\n",
    "    return subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "try:\n",
    "    sh(f\"{sys.executable} -m pip install -U fastapi uvicorn google-generativeai httpx pydantic nest_asyncio requests\")\n",
    "except Exception as e:\n",
    "    print(\"install error:\", e)\n",
    "print(\"✅ dependencies installed\")\n",
    "\n",
    "import re, json\n",
    "\n",
    "def extract_json_block(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Gemini가 코드펜스/설명/공백을 섞어 보낼 때를 대비해,\n",
    "    본문에서 첫 번째 JSON 오브젝트 블록만 안전하게 추출해 파싱한다.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"LLM 응답이 문자열이 아닙니다.\")\n",
    "\n",
    "    # 1) 코드펜스 제거 ```json ... ``` 또는 ``` ... ```\n",
    "    text = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", text.strip(), flags=re.IGNORECASE | re.MULTILINE)\n",
    "\n",
    "    # 2) 본문에서 첫 번째 { ... } 블록만 추출\n",
    "    m = re.search(r\"\\{(?:[^{}]|(?R))*\\}\", text, flags=re.DOTALL)  # 중첩 대응 (파이썬 기본 re는 (?R) 미지원이면 아래 fallback 사용)\n",
    "    if not m:\n",
    "        # Fallback: 가장 바깥쪽 중괄호 범위를 단순 탐색\n",
    "        s = text.find(\"{\")\n",
    "        e = text.rfind(\"}\")\n",
    "        if s == -1 or e == -1 or e <= s:\n",
    "            raise ValueError(\"JSON 블록을 찾지 못했습니다.\")\n",
    "        candidate = text[s:e+1]\n",
    "    else:\n",
    "        candidate = m.group(0)\n",
    "\n",
    "    # 3) 로드 시도\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # 흔한 잔여 콤마/코멘트 제거 등 최소 보정\n",
    "        cleaned = re.sub(r\"//.*?$\", \"\", candidate, flags=re.MULTILINE)             # // 주석 제거\n",
    "        cleaned = re.sub(r\",\\s*([}\\]])\", r\"\\1\", cleaned)                            # trailing comma 제거\n",
    "        return json.loads(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ca25048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FastAPI app (Gemini) ready: gemini-1.5-flash | provider: kakao\n"
     ]
    }
   ],
   "source": [
    "# FastAPI + Gemini(google-generativeai) 오케스트레이션 (Jupyter용)\n",
    "from __future__ import annotations\n",
    "import os, json, math, asyncio, traceback\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import httpx\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- 환경 변수 ---\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-1.5-flash\")\n",
    "PROVIDER_PLACES = os.getenv(\"PROVIDER_PLACES\", \"mock\").lower()\n",
    "KAKAO_REST_API_KEY = os.getenv(\"KAKAO_REST_API_KEY\", \"\")\n",
    "OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\", \"\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY가 설정되지 않았습니다.\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "\n",
    "app = FastAPI(title=\"Gemini-based Recommendations + Missions (Notebook)\")\n",
    "\n",
    "# --- 입력/출력 스키마 ---\n",
    "class UserProfile(BaseModel):\n",
    "    budget_level: Optional[int] = Field(None, ge=1, le=5)\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    allergies: List[str] = Field(default_factory=list)\n",
    "\n",
    "class Context(BaseModel):\n",
    "    lat: float\n",
    "    lng: float\n",
    "    category: str  # cafe|brunch|korean|japanese|dessert|bar\n",
    "    radius_m: int = 1500\n",
    "    when: str = \"now\"\n",
    "    party: str = \"solo\"     # solo|couple|friends|family\n",
    "    intent: str = \"casual\"  # study|work|date|celebration|casual\n",
    "    open_now: bool = True\n",
    "\n",
    "class RecommendRequest(BaseModel):\n",
    "    user_profile: UserProfile\n",
    "    context: Context\n",
    "\n",
    "class RecItem(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "    address: str = \"\"\n",
    "    reason: str\n",
    "    eta_min: int\n",
    "    expected_stay_min: int\n",
    "    crowd: str\n",
    "    link: Optional[str] = \"\"\n",
    "\n",
    "class MissionItem(BaseModel):\n",
    "    title: str\n",
    "    steps: List[str]\n",
    "    reward_hint: Optional[str] = \"\"\n",
    "\n",
    "class RecommendationPayload(BaseModel):\n",
    "    summary: str\n",
    "    recommendations: List[RecItem]\n",
    "    missions: List[MissionItem]\n",
    "\n",
    "# --- Provider 구현 ---\n",
    "def _haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    return 2*R*math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "\n",
    "def _mock_places(lat: float, lng: float, category: str) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    for i in range(10):\n",
    "        out.append({\n",
    "            \"id\": f\"mock-{category}-{i}\",\n",
    "            \"name\": f\"샘플 {category} {i+1}\",\n",
    "            \"address\": \"청주시 흥덕구 어딘가로 123\",\n",
    "            \"lat\": lat + (i * 0.0008),\n",
    "            \"lng\": lng + (i * 0.0006),\n",
    "            \"rating\": round(3.5 + (i % 3) * 0.3, 1),\n",
    "            \"price_level\": (i % 5) + 1,\n",
    "            \"features\": {\n",
    "                \"power_outlets\": i % 2 == 0,\n",
    "                \"quiet\": i % 3 != 0,\n",
    "                \"good_for_group\": i % 4 == 0,\n",
    "                \"url\": None,\n",
    "                \"distance_m\": (i + 1) * 120,\n",
    "            },\n",
    "        })\n",
    "    return out\n",
    "\n",
    "async def _kakao_places(category: str, lat: float, lng: float, radius_m: int) -> List[Dict[str, Any]]:\n",
    "    if not KAKAO_REST_API_KEY:\n",
    "        return _mock_places(lat, lng, category)\n",
    "\n",
    "    keyword_map = {\"cafe\":\"카페\",\"brunch\":\"브런치\",\"korean\":\"한식\",\"japanese\":\"일식\",\"dessert\":\"디저트\",\"bar\":\"바\"}\n",
    "    keyword = keyword_map.get(category, category)\n",
    "    url = \"https://dapi.kakao.com/v2/local/search/keyword.json\"\n",
    "    headers = {\"Authorization\": f\"KakaoAK {KAKAO_REST_API_KEY}\"}\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    async with httpx.AsyncClient(timeout=10.0) as s:\n",
    "        page = 1\n",
    "        while page <= 2:\n",
    "            params = {\"query\": keyword, \"x\": str(lng), \"y\": str(lat),\n",
    "                      \"radius\": str(min(max(radius_m,100),20000)),\n",
    "                      \"page\": page, \"size\": 15, \"sort\": \"distance\"}\n",
    "            r = await s.get(url, headers=headers, params=params)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            for d in data.get(\"documents\", []):\n",
    "                items.append({\n",
    "                    \"id\": d.get(\"id\"),\n",
    "                    \"name\": d.get(\"place_name\"),\n",
    "                    \"address\": d.get(\"road_address_name\") or d.get(\"address_name\"),\n",
    "                    \"lat\": float(d.get(\"y\")),\n",
    "                    \"lng\": float(d.get(\"x\")),\n",
    "                    \"rating\": None,\n",
    "                    \"price_level\": None,\n",
    "                    \"features\": {\n",
    "                        \"url\": d.get(\"place_url\"),\n",
    "                        \"category\": d.get(\"category_group_name\"),\n",
    "                        \"distance_m\": _haversine_m(lat, lng, float(d.get(\"y\")), float(d.get(\"x\"))),\n",
    "                    },\n",
    "                })\n",
    "            if data.get(\"meta\", {}).get(\"is_end\"):\n",
    "                break\n",
    "            page += 1\n",
    "    return items\n",
    "\n",
    "async def _openweather(lat: float, lng: float) -> Dict[str, Any]:\n",
    "    if not OPENWEATHER_API_KEY:\n",
    "        return {\"when\":\"now\",\"status\":\"clouds\",\"temp_c\":26.0,\"rain_prob\":0.2}\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"lat\":lat, \"lon\":lng, \"appid\":OPENWEATHER_API_KEY, \"units\":\"metric\"}\n",
    "    async with httpx.AsyncClient(timeout=8.0) as s:\n",
    "        r = await s.get(url, params=params)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "    wx = data.get(\"weather\", [{}])[0].get(\"main\", \"Clouds\").lower()\n",
    "    temp = data.get(\"main\", {}).get(\"temp\", None)\n",
    "    rain = data.get(\"rain\", {}).get(\"1h\", 0.0)\n",
    "    return {\"when\":\"now\",\"status\":wx,\"temp_c\":temp,\"rain_prob\":0.6 if rain else 0.1}\n",
    "\n",
    "async def provider_search_places(category: str, lat: float, lng: float, radius_m: int) -> List[Dict[str, Any]]:\n",
    "    if PROVIDER_PLACES == \"kakao\":\n",
    "        return await _kakao_places(category, lat, lng, radius_m)\n",
    "    return _mock_places(lat, lng, category)\n",
    "\n",
    "async def provider_get_weather(lat: float, lng: float, when: str) -> Dict[str, Any]:\n",
    "    return await _openweather(lat, lng)\n",
    "\n",
    "# --- Gemini 호출 유틸 ---\n",
    "PROMPT = \"\"\"당신은 지역 추천 큐레이터입니다.\n",
    "아래 입력을 바탕으로 Top5 장소 추천과 상황 맞춤 미션을 JSON으로만 반환하세요.\n",
    "\n",
    "규칙:\n",
    "- 반드시 JSON만 출력\n",
    "- 각 추천에는 reason, eta_min(분), expected_stay_min(분), crowd(low/medium/high), 가능한 link 포함\n",
    "- 미션은 2~3개: 구체적/측정가능(시간/수량), 메뉴와 연결, 가벼운 게임화\n",
    "\n",
    "입력:\n",
    "user_profile = {user_profile}\n",
    "context = {context}\n",
    "candidates = {candidates}\n",
    "weather = {weather}\n",
    "\n",
    "JSON 스키마:\n",
    "{\n",
    "  \"summary\": \"string\",\n",
    "  \"recommendations\": [\n",
    "    {\n",
    "      \"id\": \"string\",\n",
    "      \"name\": \"string\",\n",
    "      \"address\": \"string\",\n",
    "      \"reason\": \"string\",\n",
    "      \"eta_min\": 0,\n",
    "      \"expected_stay_min\": 0,\n",
    "      \"crowd\": \"low|medium|high\",\n",
    "      \"link\": \"string\"\n",
    "    }\n",
    "  ],\n",
    "  \"missions\": [\n",
    "    {\n",
    "      \"title\": \"string\",\n",
    "      \"steps\": [\"string\", \"...\"],\n",
    "      \"reward_hint\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "async def call_gemini_json(user_profile: dict, context: dict, candidates: list, weather: dict) -> dict:\n",
    "    content = PROMPT.format(\n",
    "        user_profile=json.dumps(user_profile, ensure_ascii=False),\n",
    "        context=json.dumps(context, ensure_ascii=False),\n",
    "        candidates=json.dumps(candidates[:20], ensure_ascii=False),\n",
    "        weather=json.dumps(weather, ensure_ascii=False),\n",
    "    )\n",
    "    resp = model.generate_content(\n",
    "        content,\n",
    "        generation_config={\n",
    "            \"temperature\": 0.15,                 # (0) 추가 수정: 더 안정적으로\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "        }\n",
    "    )\n",
    "    text = resp.text or \"\"                        # (1) 그대로 두기\n",
    "    if not text.strip():\n",
    "        raise RuntimeError(\"Gemini가 빈 응답을 반환했습니다.\")\n",
    "\n",
    "    # (2) 여기 교체\n",
    "    # 원래: data = json.loads(text)\n",
    "    data = extract_json_block(text)\n",
    "\n",
    "    # (3) 누락 필드 기본값 보정\n",
    "    for rec in data.get(\"recommendations\", []):\n",
    "        rec.setdefault(\"address\", \"\")\n",
    "        rec.setdefault(\"link\", \"\")\n",
    "\n",
    "    # (4) 검증\n",
    "    try:\n",
    "        payload = RecommendationPayload(**data)\n",
    "        return payload.model_dump()\n",
    "    except ValidationError as ve:\n",
    "        raise HTTPException(status_code=500, detail=f\"Schema validation failed: {ve.errors()}\")\n",
    "\n",
    "    # Pydantic 검증 + 누락 필드 기본값 보정\n",
    "    try:\n",
    "        # address/link 누락 대비 기본값 처리\n",
    "        for rec in data.get(\"recommendations\", []):\n",
    "            rec.setdefault(\"address\", \"\")\n",
    "            rec.setdefault(\"link\", \"\")\n",
    "        payload = RecommendationPayload(**data)\n",
    "        return payload.model_dump()\n",
    "    except ValidationError as ve:\n",
    "        # 한 번 더 보정해보고 실패하면 에러\n",
    "        raise HTTPException(status_code=500, detail=f\"Schema validation failed: {ve.errors()}\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"JSON parse/validate error: {e}\")\n",
    "\n",
    "# --- 전역 예외 핸들러 (항상 JSON 반환) ---\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.requests import Request\n",
    "from starlette.exceptions import HTTPException as StarletteHTTPException\n",
    "\n",
    "@app.exception_handler(StarletteHTTPException)\n",
    "async def http_exception_handler(request: Request, exc: StarletteHTTPException):\n",
    "    return JSONResponse(status_code=exc.status_code, content={\"type\":\"http_exception\",\"detail\":exc.detail})\n",
    "\n",
    "@app.exception_handler(Exception)\n",
    "async def unhandled_exception_handler(request: Request, exc: Exception):\n",
    "    tb = \"\".join(traceback.format_exception(type(exc), exc, exc.__traceback__))\n",
    "    return JSONResponse(status_code=500, content={\"type\":\"server_exception\",\"detail\":str(exc),\"trace\":tb[:2000]})\n",
    "\n",
    "# --- 엔드포인트 ---\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"ok\": True, \"model\": GEMINI_MODEL, \"places_provider\": PROVIDER_PLACES}\n",
    "\n",
    "@app.get(\"/selftest/gemini\")\n",
    "async def selftest_gemini():\n",
    "    try:\n",
    "        r = model.generate_content(\n",
    "            \"JSON 한 줄로 {\\\"ok\\\": true} 형태로만 응답\",\n",
    "            generation_config={\"response_mime_type\": \"application/json\"},\n",
    "        )\n",
    "        return {\"ok\": True, \"model\": GEMINI_MODEL, \"sample\": json.loads(r.text)}\n",
    "    except Exception as e:\n",
    "        return {\"ok\": False, \"model\": GEMINI_MODEL, \"error\": str(e)}\n",
    "\n",
    "# 임시: LLM 완전 모의 응답(UX 확인용)\n",
    "FORCE_MOCK_LLM = False\n",
    "MOCK_RESPONSE = {\n",
    "    \"summary\": \"샘플 추천 결과\",\n",
    "    \"recommendations\": [\n",
    "        {\"id\":\"mock-cafe-1\",\"name\":\"샘플 카페 1\",\"address\":\"샘플 주소\",\"reason\":\"조용+콘센트\",\"eta_min\":7,\"expected_stay_min\":90,\"crowd\":\"medium\",\"link\":\"\"}\n",
    "    ],\n",
    "    \"missions\":[\n",
    "        {\"title\":\"집중 코딩 45분\",\"steps\":[\"시그니처 라떼 주문\",\"45분 집중\",\"15분 산책\"],\"reward_hint\":\"디저트 1개\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "@app.post(\"/recommend\")\n",
    "async def recommend(req: RecommendRequest, debug: bool = False):\n",
    "    # provider 스모크 테스트\n",
    "    try:\n",
    "        _ = await provider_search_places(req.context.category, req.context.lat, req.context.lng, req.context.radius_m)\n",
    "        _ = await provider_get_weather(req.context.lat, req.context.lng, req.context.when)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"provider_error: {e}\")\n",
    "\n",
    "    if debug:\n",
    "        cands = await provider_search_places(req.context.category, req.context.lat, req.context.lng, req.context.radius_m)\n",
    "        wx = await provider_get_weather(req.context.lat, req.context.lng, req.context.when)\n",
    "        return {\"summary\":\"debug bypass\",\"recommendations\":[],\"missions\":[],\"_debug\":{\"candidates_len\":len(cands),\"weather\":wx}}\n",
    "\n",
    "    if FORCE_MOCK_LLM:\n",
    "        return MOCK_RESPONSE\n",
    "\n",
    "    # 정상 경로: 후보/날씨 수집 → Gemini로 리랭킹/생성\n",
    "    cands = await provider_search_places(req.context.category, req.context.lat, req.context.lng, req.context.radius_m)\n",
    "    wx = await provider_get_weather(req.context.lat, req.context.lng, req.context.when)\n",
    "    return await call_gemini_json(req.user_profile.model_dump(), req.context.model_dump(), cands, wx)\n",
    "\n",
    "print(\"✅ FastAPI app (Gemini) ready:\", GEMINI_MODEL, \"| provider:\", PROVIDER_PLACES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e3519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Uvicorn at http://127.0.0.1:8020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [19628]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8023 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52914 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52915 - \"GET /selftest/gemini HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52917 - \"POST /recommend?debug=true HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52922 - \"POST /recommend HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.scope, self.receive, self.send\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 78, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 302, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 213, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\1898134286.py\", line 291, in recommend\n",
      "    return await call_gemini_json(req.user_profile.model_dump(), req.context.model_dump(), cands, wx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\1898134286.py\", line 197, in call_gemini_json\n",
      "    content = PROMPT.format(\n",
      "        user_profile=json.dumps(user_profile, ensure_ascii=False),\n",
      "    ...<2 lines>...\n",
      "        weather=json.dumps(weather, ensure_ascii=False),\n",
      "    )\n",
      "KeyError: '\\n  \"summary\"'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51977 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51978 - \"GET /selftest/gemini HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51980 - \"POST /recommend?debug=true HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51985 - \"POST /recommend HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.scope, self.receive, self.send\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 78, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 302, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 213, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\1898134286.py\", line 291, in recommend\n",
      "    return await call_gemini_json(req.user_profile.model_dump(), req.context.model_dump(), cands, wx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\2999851431.py\", line 197, in call_gemini_json\n",
      "    content = PROMPT.format(\n",
      "        user_profile=json.dumps(user_profile, ensure_ascii=False),\n",
      "    ...<2 lines>...\n",
      "        weather=json.dumps(weather, ensure_ascii=False),\n",
      "    )\n",
      "KeyError: '\\n  \"summary\"'\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio, threading, uvicorn\n",
    "nest_asyncio.apply()\n",
    "\n",
    "PORT = 8020\n",
    "config = uvicorn.Config(app, host=\"127.0.0.1\", port=8023, log_level=\"info\")\n",
    "server = uvicorn.Server(config)\n",
    "\n",
    "t = threading.Thread(target=server.run, daemon=True)\n",
    "t.start()\n",
    "print(f\"🚀 Uvicorn at http://127.0.0.1:{PORT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7dd5b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROOT /] 200 | application/json | 64 bytes\n",
      "{\"ok\":true,\"model\":\"gemini-1.5-flash\",\"places_provider\":\"kakao\"}\n",
      "------------------------------------------------------------\n",
      "[SELFTEST /selftest/gemini] 200 | application/json | 59 bytes\n",
      "{\"ok\":true,\"model\":\"gemini-1.5-flash\",\"sample\":{\"ok\":true}}\n",
      "------------------------------------------------------------\n",
      "[RECO DEBUG /recommend?debug=true] 200 | application/json | 165 bytes\n",
      "{\"summary\":\"debug bypass\",\"recommendations\":[],\"missions\":[],\"_debug\":{\"candidates_len\":30,\"weather\":{\"when\":\"now\",\"status\":\"clear\",\"temp_c\":29.01,\"rain_prob\":0.1}}}\n",
      "------------------------------------------------------------\n",
      "[RECO FULL /recommend] 500 | application/json | 2240 bytes\n",
      "{\"type\":\"server_exception\",\"detail\":\"'\\\\n  \\\"summary\\\"'\",\"trace\":\"Traceback (most recent call last):\\n  File \\\"c:\\\\Users\\\\sj021\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\starlette\\\\middleware\\\\errors.py\\\", line 164, in __call__\\n    await self.app(scope, receive, _send)\\n  Fi ...[truncated]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "BASE = \"http://127.0.0.1:8023\"\n",
    "\n",
    "def brief(r, name):\n",
    "    print(f\"[{name}] {r.status_code} | {r.headers.get('content-type')} | {len(r.content)} bytes\")\n",
    "    print(r.text[:300] + (\" ...[truncated]\" if len(r.text)>300 else \"\"))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "# 5-1) 루트\n",
    "r = requests.get(f\"{BASE}/\", timeout=10)\n",
    "brief(r, \"ROOT /\")\n",
    "\n",
    "# 5-2) Gemini 셀프테스트\n",
    "r = requests.get(f\"{BASE}/selftest/gemini\", timeout=30)\n",
    "brief(r, \"SELFTEST /selftest/gemini\")\n",
    "\n",
    "# 5-3) /recommend (LLM 우회)\n",
    "payload = {\n",
    "    \"user_profile\": {\"budget_level\": 2, \"tags\": [\"조용\",\"콘센트\"], \"allergies\": [\"견과\"]},\n",
    "    \"context\": {\n",
    "        \"lat\": 36.6424, \"lng\": 127.4887, \"category\": \"cafe\",\n",
    "        \"radius_m\": 1500, \"when\": \"today_evening\",\n",
    "        \"party\": \"solo\", \"intent\": \"study\", \"open_now\": True\n",
    "    }\n",
    "}\n",
    "r = requests.post(f\"{BASE}/recommend?debug=true\", json=payload, timeout=60)\n",
    "brief(r, \"RECO DEBUG /recommend?debug=true\")\n",
    "\n",
    "# 5-4) /recommend (정상 경로: Gemini 포함)\n",
    "r = requests.post(f\"{BASE}/recommend\", json=payload, timeout=120)\n",
    "brief(r, \"RECO FULL /recommend\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6281d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
