{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c309dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Keys set in environment (this kernel).\n",
      "MODEL= gemini-1.5-flash | PROVIDER_PLACES= kakao\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ğŸ” ì—¬ê¸°ì— ë„ˆì˜ ì‹¤ì œ Gemini API í‚¤ë¥¼ ë„£ì–´ì¤˜ (ì˜ˆ: AIza... í˜•íƒœ)\n",
    "GEMINI_API_KEY     = \"AIzaSyBQZf_zvXm4lLU0FuWmCUyzIb58V8MtTP0\"\n",
    "# Kakao/OpenWeatherëŠ” ì›í•  ë•Œë§Œ(ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´/ëª¨ì˜ ë™ì‘)\n",
    "KAKAO_REST_API_KEY = \"a09b700883a323951739abd49bce2a7a\"\n",
    "OPENWEATHER_API_KEY = \"6f0a079ee5a654b20ca8705d2ebd974a\"\n",
    "\n",
    "# ì¥ì†Œ ì œê³µì: \"mock\"(ê¸°ë³¸) ë˜ëŠ” \"kakao\"\n",
    "PLACES_PROVIDER = \"kakao\"  # kakao ì“°ë ¤ë©´ \"kakao\"\n",
    "\n",
    "# ëª¨ë¸ì€ ë¬´ë£Œ ì¿¼í„° ë„‰ë„‰í•œ 'flash' ì¶”ì²œ. ë” ì„±ëŠ¥ ì›í•˜ë©´ \"gemini-1.5-pro\"\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# â–¶ OS í™˜ê²½ ë³€ìˆ˜ ì£¼ì…\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "os.environ[\"GEMINI_MODEL\"] = GEMINI_MODEL\n",
    "os.environ[\"PROVIDER_PLACES\"] = PLACES_PROVIDER\n",
    "os.environ[\"KAKAO_REST_API_KEY\"] = KAKAO_REST_API_KEY\n",
    "os.environ[\"OPENWEATHER_API_KEY\"] = OPENWEATHER_API_KEY\n",
    "\n",
    "print(\"âœ… Keys set in environment (this kernel).\")\n",
    "print(\"MODEL=\", os.getenv(\"GEMINI_MODEL\"), \"| PROVIDER_PLACES=\", os.getenv(\"PROVIDER_PLACES\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ed2fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install -U fastapi uvicorn google-generativeai httpx pydantic nest_asyncio requests\n",
      "âœ… dependencies installed\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "def sh(cmd):\n",
    "    print(\">\", cmd)\n",
    "    return subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "try:\n",
    "    sh(f\"{sys.executable} -m pip install -U fastapi uvicorn google-generativeai httpx pydantic nest_asyncio requests\")\n",
    "except Exception as e:\n",
    "    print(\"install error:\", e)\n",
    "print(\"âœ… dependencies installed\")\n",
    "\n",
    "import re, json\n",
    "\n",
    "def extract_json_block(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Geminiê°€ ì½”ë“œíœìŠ¤/ì„¤ëª…/ê³µë°±ì„ ì„ì–´ ë³´ë‚¼ ë•Œë¥¼ ëŒ€ë¹„í•´,\n",
    "    ë³¸ë¬¸ì—ì„œ ì²« ë²ˆì§¸ JSON ì˜¤ë¸Œì íŠ¸ ë¸”ë¡ë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•´ íŒŒì‹±í•œë‹¤.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"LLM ì‘ë‹µì´ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤.\")\n",
    "\n",
    "    # 1) ì½”ë“œíœìŠ¤ ì œê±° ```json ... ``` ë˜ëŠ” ``` ... ```\n",
    "    text = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", text.strip(), flags=re.IGNORECASE | re.MULTILINE)\n",
    "\n",
    "    # 2) ë³¸ë¬¸ì—ì„œ ì²« ë²ˆì§¸ { ... } ë¸”ë¡ë§Œ ì¶”ì¶œ\n",
    "    m = re.search(r\"\\{(?:[^{}]|(?R))*\\}\", text, flags=re.DOTALL)  # ì¤‘ì²© ëŒ€ì‘ (íŒŒì´ì¬ ê¸°ë³¸ reëŠ” (?R) ë¯¸ì§€ì›ì´ë©´ ì•„ë˜ fallback ì‚¬ìš©)\n",
    "    if not m:\n",
    "        # Fallback: ê°€ì¥ ë°”ê¹¥ìª½ ì¤‘ê´„í˜¸ ë²”ìœ„ë¥¼ ë‹¨ìˆœ íƒìƒ‰\n",
    "        s = text.find(\"{\")\n",
    "        e = text.rfind(\"}\")\n",
    "        if s == -1 or e == -1 or e <= s:\n",
    "            raise ValueError(\"JSON ë¸”ë¡ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        candidate = text[s:e+1]\n",
    "    else:\n",
    "        candidate = m.group(0)\n",
    "\n",
    "    # 3) ë¡œë“œ ì‹œë„\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # í”í•œ ì”ì—¬ ì½¤ë§ˆ/ì½”ë©˜íŠ¸ ì œê±° ë“± ìµœì†Œ ë³´ì •\n",
    "        cleaned = re.sub(r\"//.*?$\", \"\", candidate, flags=re.MULTILINE)             # // ì£¼ì„ ì œê±°\n",
    "        cleaned = re.sub(r\",\\s*([}\\]])\", r\"\\1\", cleaned)                            # trailing comma ì œê±°\n",
    "        return json.loads(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ca25048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FastAPI app (Gemini) ready: gemini-1.5-flash | provider: kakao\n"
     ]
    }
   ],
   "source": [
    "# FastAPI + Gemini(google-generativeai) ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (Jupyterìš©)\n",
    "from __future__ import annotations\n",
    "import os, json, math, asyncio, traceback\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import httpx\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- í™˜ê²½ ë³€ìˆ˜ ---\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-1.5-flash\")\n",
    "PROVIDER_PLACES = os.getenv(\"PROVIDER_PLACES\", \"mock\").lower()\n",
    "KAKAO_REST_API_KEY = os.getenv(\"KAKAO_REST_API_KEY\", \"\")\n",
    "OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\", \"\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\"GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "\n",
    "app = FastAPI(title=\"Gemini-based Recommendations + Missions (Notebook)\")\n",
    "\n",
    "# --- ì…ë ¥/ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ---\n",
    "class UserProfile(BaseModel):\n",
    "    budget_level: Optional[int] = Field(None, ge=1, le=5)\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    allergies: List[str] = Field(default_factory=list)\n",
    "\n",
    "class Context(BaseModel):\n",
    "    lat: float\n",
    "    lng: float\n",
    "    category: str  # cafe|brunch|korean|japanese|dessert|bar\n",
    "    radius_m: int = 1500\n",
    "    when: str = \"now\"\n",
    "    party: str = \"solo\"     # solo|couple|friends|family\n",
    "    intent: str = \"casual\"  # study|work|date|celebration|casual\n",
    "    open_now: bool = True\n",
    "\n",
    "class RecommendRequest(BaseModel):\n",
    "    user_profile: UserProfile\n",
    "    context: Context\n",
    "\n",
    "class RecItem(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "    address: str = \"\"\n",
    "    reason: str\n",
    "    eta_min: int\n",
    "    expected_stay_min: int\n",
    "    crowd: str\n",
    "    link: Optional[str] = \"\"\n",
    "\n",
    "class MissionItem(BaseModel):\n",
    "    title: str\n",
    "    steps: List[str]\n",
    "    reward_hint: Optional[str] = \"\"\n",
    "\n",
    "class RecommendationPayload(BaseModel):\n",
    "    summary: str\n",
    "    recommendations: List[RecItem]\n",
    "    missions: List[MissionItem]\n",
    "\n",
    "# --- Provider êµ¬í˜„ ---\n",
    "def _haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    return 2*R*math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "\n",
    "def _mock_places(lat: float, lng: float, category: str) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    for i in range(10):\n",
    "        out.append({\n",
    "            \"id\": f\"mock-{category}-{i}\",\n",
    "            \"name\": f\"ìƒ˜í”Œ {category} {i+1}\",\n",
    "            \"address\": \"ì²­ì£¼ì‹œ í¥ë•êµ¬ ì–´ë”˜ê°€ë¡œ 123\",\n",
    "            \"lat\": lat + (i * 0.0008),\n",
    "            \"lng\": lng + (i * 0.0006),\n",
    "            \"rating\": round(3.5 + (i % 3) * 0.3, 1),\n",
    "            \"price_level\": (i % 5) + 1,\n",
    "            \"features\": {\n",
    "                \"power_outlets\": i % 2 == 0,\n",
    "                \"quiet\": i % 3 != 0,\n",
    "                \"good_for_group\": i % 4 == 0,\n",
    "                \"url\": None,\n",
    "                \"distance_m\": (i + 1) * 120,\n",
    "            },\n",
    "        })\n",
    "    return out\n",
    "\n",
    "async def _kakao_places(category: str, lat: float, lng: float, radius_m: int) -> List[Dict[str, Any]]:\n",
    "    if not KAKAO_REST_API_KEY:\n",
    "        return _mock_places(lat, lng, category)\n",
    "\n",
    "    keyword_map = {\"cafe\":\"ì¹´í˜\",\"brunch\":\"ë¸ŒëŸ°ì¹˜\",\"korean\":\"í•œì‹\",\"japanese\":\"ì¼ì‹\",\"dessert\":\"ë””ì €íŠ¸\",\"bar\":\"ë°”\"}\n",
    "    keyword = keyword_map.get(category, category)\n",
    "    url = \"https://dapi.kakao.com/v2/local/search/keyword.json\"\n",
    "    headers = {\"Authorization\": f\"KakaoAK {KAKAO_REST_API_KEY}\"}\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    async with httpx.AsyncClient(timeout=10.0) as s:\n",
    "        page = 1\n",
    "        while page <= 2:\n",
    "            params = {\"query\": keyword, \"x\": str(lng), \"y\": str(lat),\n",
    "                      \"radius\": str(min(max(radius_m,100),20000)),\n",
    "                      \"page\": page, \"size\": 15, \"sort\": \"distance\"}\n",
    "            r = await s.get(url, headers=headers, params=params)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            for d in data.get(\"documents\", []):\n",
    "                items.append({\n",
    "                    \"id\": d.get(\"id\"),\n",
    "                    \"name\": d.get(\"place_name\"),\n",
    "                    \"address\": d.get(\"road_address_name\") or d.get(\"address_name\"),\n",
    "                    \"lat\": float(d.get(\"y\")),\n",
    "                    \"lng\": float(d.get(\"x\")),\n",
    "                    \"rating\": None,\n",
    "                    \"price_level\": None,\n",
    "                    \"features\": {\n",
    "                        \"url\": d.get(\"place_url\"),\n",
    "                        \"category\": d.get(\"category_group_name\"),\n",
    "                        \"distance_m\": _haversine_m(lat, lng, float(d.get(\"y\")), float(d.get(\"x\"))),\n",
    "                    },\n",
    "                })\n",
    "            if data.get(\"meta\", {}).get(\"is_end\"):\n",
    "                break\n",
    "            page += 1\n",
    "    return items\n",
    "\n",
    "async def _openweather(lat: float, lng: float) -> Dict[str, Any]:\n",
    "    if not OPENWEATHER_API_KEY:\n",
    "        return {\"when\":\"now\",\"status\":\"clouds\",\"temp_c\":26.0,\"rain_prob\":0.2}\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"lat\":lat, \"lon\":lng, \"appid\":OPENWEATHER_API_KEY, \"units\":\"metric\"}\n",
    "    async with httpx.AsyncClient(timeout=8.0) as s:\n",
    "        r = await s.get(url, params=params)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "    wx = data.get(\"weather\", [{}])[0].get(\"main\", \"Clouds\").lower()\n",
    "    temp = data.get(\"main\", {}).get(\"temp\", None)\n",
    "    rain = data.get(\"rain\", {}).get(\"1h\", 0.0)\n",
    "    return {\"when\":\"now\",\"status\":wx,\"temp_c\":temp,\"rain_prob\":0.6 if rain else 0.1}\n",
    "\n",
    "async def provider_search_places(category: str, lat: float, lng: float, radius_m: int) -> List[Dict[str, Any]]:\n",
    "    if PROVIDER_PLACES == \"kakao\":\n",
    "        return await _kakao_places(category, lat, lng, radius_m)\n",
    "    return _mock_places(lat, lng, category)\n",
    "\n",
    "async def provider_get_weather(lat: float, lng: float, when: str) -> Dict[str, Any]:\n",
    "    return await _openweather(lat, lng)\n",
    "\n",
    "# --- Gemini í˜¸ì¶œ ìœ í‹¸ ---\n",
    "PROMPT = \"\"\"ë‹¹ì‹ ì€ ì§€ì—­ ì¶”ì²œ íë ˆì´í„°ì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ Top5 ì¥ì†Œ ì¶”ì²œê³¼ ìƒí™© ë§ì¶¤ ë¯¸ì…˜ì„ JSONìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.\n",
    "\n",
    "ê·œì¹™:\n",
    "- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥\n",
    "- ê° ì¶”ì²œì—ëŠ” reason, eta_min(ë¶„), expected_stay_min(ë¶„), crowd(low/medium/high), ê°€ëŠ¥í•œ link í¬í•¨\n",
    "- ë¯¸ì…˜ì€ 2~3ê°œ: êµ¬ì²´ì /ì¸¡ì •ê°€ëŠ¥(ì‹œê°„/ìˆ˜ëŸ‰), ë©”ë‰´ì™€ ì—°ê²°, ê°€ë²¼ìš´ ê²Œì„í™”\n",
    "\n",
    "ì…ë ¥:\n",
    "user_profile = {user_profile}\n",
    "context = {context}\n",
    "candidates = {candidates}\n",
    "weather = {weather}\n",
    "\n",
    "JSON ìŠ¤í‚¤ë§ˆ:\n",
    "{\n",
    "  \"summary\": \"string\",\n",
    "  \"recommendations\": [\n",
    "    {\n",
    "      \"id\": \"string\",\n",
    "      \"name\": \"string\",\n",
    "      \"address\": \"string\",\n",
    "      \"reason\": \"string\",\n",
    "      \"eta_min\": 0,\n",
    "      \"expected_stay_min\": 0,\n",
    "      \"crowd\": \"low|medium|high\",\n",
    "      \"link\": \"string\"\n",
    "    }\n",
    "  ],\n",
    "  \"missions\": [\n",
    "    {\n",
    "      \"title\": \"string\",\n",
    "      \"steps\": [\"string\", \"...\"],\n",
    "      \"reward_hint\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "async def call_gemini_json(user_profile: dict, context: dict, candidates: list, weather: dict) -> dict:\n",
    "    content = PROMPT.format(\n",
    "        user_profile=json.dumps(user_profile, ensure_ascii=False),\n",
    "        context=json.dumps(context, ensure_ascii=False),\n",
    "        candidates=json.dumps(candidates[:20], ensure_ascii=False),\n",
    "        weather=json.dumps(weather, ensure_ascii=False),\n",
    "    )\n",
    "    resp = model.generate_content(\n",
    "        content,\n",
    "        generation_config={\n",
    "            \"temperature\": 0.15,                 # (0) ì¶”ê°€ ìˆ˜ì •: ë” ì•ˆì •ì ìœ¼ë¡œ\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "        }\n",
    "    )\n",
    "    text = resp.text or \"\"                        # (1) ê·¸ëŒ€ë¡œ ë‘ê¸°\n",
    "    if not text.strip():\n",
    "        raise RuntimeError(\"Geminiê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # (2) ì—¬ê¸° êµì²´\n",
    "    # ì›ë˜: data = json.loads(text)\n",
    "    data = extract_json_block(text)\n",
    "\n",
    "    # (3) ëˆ„ë½ í•„ë“œ ê¸°ë³¸ê°’ ë³´ì •\n",
    "    for rec in data.get(\"recommendations\", []):\n",
    "        rec.setdefault(\"address\", \"\")\n",
    "        rec.setdefault(\"link\", \"\")\n",
    "\n",
    "    # (4) ê²€ì¦\n",
    "    try:\n",
    "        payload = RecommendationPayload(**data)\n",
    "        return payload.model_dump()\n",
    "    except ValidationError as ve:\n",
    "        raise HTTPException(status_code=500, detail=f\"Schema validation failed: {ve.errors()}\")\n",
    "\n",
    "    # Pydantic ê²€ì¦ + ëˆ„ë½ í•„ë“œ ê¸°ë³¸ê°’ ë³´ì •\n",
    "    try:\n",
    "        # address/link ëˆ„ë½ ëŒ€ë¹„ ê¸°ë³¸ê°’ ì²˜ë¦¬\n",
    "        for rec in data.get(\"recommendations\", []):\n",
    "            rec.setdefault(\"address\", \"\")\n",
    "            rec.setdefault(\"link\", \"\")\n",
    "        payload = RecommendationPayload(**data)\n",
    "        return payload.model_dump()\n",
    "    except ValidationError as ve:\n",
    "        # í•œ ë²ˆ ë” ë³´ì •í•´ë³´ê³  ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬\n",
    "        raise HTTPException(status_code=500, detail=f\"Schema validation failed: {ve.errors()}\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"JSON parse/validate error: {e}\")\n",
    "\n",
    "# --- ì „ì—­ ì˜ˆì™¸ í•¸ë“¤ëŸ¬ (í•­ìƒ JSON ë°˜í™˜) ---\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.requests import Request\n",
    "from starlette.exceptions import HTTPException as StarletteHTTPException\n",
    "\n",
    "@app.exception_handler(StarletteHTTPException)\n",
    "async def http_exception_handler(request: Request, exc: StarletteHTTPException):\n",
    "    return JSONResponse(status_code=exc.status_code, content={\"type\":\"http_exception\",\"detail\":exc.detail})\n",
    "\n",
    "@app.exception_handler(Exception)\n",
    "async def unhandled_exception_handler(request: Request, exc: Exception):\n",
    "    tb = \"\".join(traceback.format_exception(type(exc), exc, exc.__traceback__))\n",
    "    return JSONResponse(status_code=500, content={\"type\":\"server_exception\",\"detail\":str(exc),\"trace\":tb[:2000]})\n",
    "\n",
    "# --- ì—”ë“œí¬ì¸íŠ¸ ---\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"ok\": True, \"model\": GEMINI_MODEL, \"places_provider\": PROVIDER_PLACES}\n",
    "\n",
    "@app.get(\"/selftest/gemini\")\n",
    "async def selftest_gemini():\n",
    "    try:\n",
    "        r = model.generate_content(\n",
    "            \"JSON í•œ ì¤„ë¡œ {\\\"ok\\\": true} í˜•íƒœë¡œë§Œ ì‘ë‹µ\",\n",
    "            generation_config={\"response_mime_type\": \"application/json\"},\n",
    "        )\n",
    "        return {\"ok\": True, \"model\": GEMINI_MODEL, \"sample\": json.loads(r.text)}\n",
    "    except Exception as e:\n",
    "        return {\"ok\": False, \"model\": GEMINI_MODEL, \"error\": str(e)}\n",
    "\n",
    "# ì„ì‹œ: LLM ì™„ì „ ëª¨ì˜ ì‘ë‹µ(UX í™•ì¸ìš©)\n",
    "FORCE_MOCK_LLM = False\n",
    "MOCK_RESPONSE = {\n",
    "    \"summary\": \"ìƒ˜í”Œ ì¶”ì²œ ê²°ê³¼\",\n",
    "    \"recommendations\": [\n",
    "        {\"id\":\"mock-cafe-1\",\"name\":\"ìƒ˜í”Œ ì¹´í˜ 1\",\"address\":\"ìƒ˜í”Œ ì£¼ì†Œ\",\"reason\":\"ì¡°ìš©+ì½˜ì„¼íŠ¸\",\"eta_min\":7,\"expected_stay_min\":90,\"crowd\":\"medium\",\"link\":\"\"}\n",
    "    ],\n",
    "    \"missions\":[\n",
    "        {\"title\":\"ì§‘ì¤‘ ì½”ë”© 45ë¶„\",\"steps\":[\"ì‹œê·¸ë‹ˆì²˜ ë¼ë–¼ ì£¼ë¬¸\",\"45ë¶„ ì§‘ì¤‘\",\"15ë¶„ ì‚°ì±…\"],\"reward_hint\":\"ë””ì €íŠ¸ 1ê°œ\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "@app.post(\"/recommend\")\n",
    "async def recommend(req: RecommendRequest, debug: bool = False):\n",
    "    # provider ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸\n",
    "    try:\n",
    "        _ = await provider_search_places(req.context.category, req.context.lat, req.context.lng, req.context.radius_m)\n",
    "        _ = await provider_get_weather(req.context.lat, req.context.lng, req.context.when)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"provider_error: {e}\")\n",
    "\n",
    "    if debug:\n",
    "        cands = await provider_search_places(req.context.category, req.context.lat, req.context.lng, req.context.radius_m)\n",
    "        wx = await provider_get_weather(req.context.lat, req.context.lng, req.context.when)\n",
    "        return {\"summary\":\"debug bypass\",\"recommendations\":[],\"missions\":[],\"_debug\":{\"candidates_len\":len(cands),\"weather\":wx}}\n",
    "\n",
    "    if FORCE_MOCK_LLM:\n",
    "        return MOCK_RESPONSE\n",
    "\n",
    "    # ì •ìƒ ê²½ë¡œ: í›„ë³´/ë‚ ì”¨ ìˆ˜ì§‘ â†’ Geminië¡œ ë¦¬ë­í‚¹/ìƒì„±\n",
    "    cands = await provider_search_places(req.context.category, req.context.lat, req.context.lng, req.context.radius_m)\n",
    "    wx = await provider_get_weather(req.context.lat, req.context.lng, req.context.when)\n",
    "    return await call_gemini_json(req.user_profile.model_dump(), req.context.model_dump(), cands, wx)\n",
    "\n",
    "print(\"âœ… FastAPI app (Gemini) ready:\", GEMINI_MODEL, \"| provider:\", PROVIDER_PLACES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e3519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Uvicorn at http://127.0.0.1:8020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [19628]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8023 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52914 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52915 - \"GET /selftest/gemini HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52917 - \"POST /recommend?debug=true HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52922 - \"POST /recommend HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.scope, self.receive, self.send\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 78, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 302, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 213, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\1898134286.py\", line 291, in recommend\n",
      "    return await call_gemini_json(req.user_profile.model_dump(), req.context.model_dump(), cands, wx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\1898134286.py\", line 197, in call_gemini_json\n",
      "    content = PROMPT.format(\n",
      "        user_profile=json.dumps(user_profile, ensure_ascii=False),\n",
      "    ...<2 lines>...\n",
      "        weather=json.dumps(weather, ensure_ascii=False),\n",
      "    )\n",
      "KeyError: '\\n  \"summary\"'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51977 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51978 - \"GET /selftest/gemini HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51980 - \"POST /recommend?debug=true HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51985 - \"POST /recommend HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.scope, self.receive, self.send\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 78, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 302, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sj021\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fastapi\\routing.py\", line 213, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\1898134286.py\", line 291, in recommend\n",
      "    return await call_gemini_json(req.user_profile.model_dump(), req.context.model_dump(), cands, wx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sj021\\AppData\\Local\\Temp\\ipykernel_19628\\2999851431.py\", line 197, in call_gemini_json\n",
      "    content = PROMPT.format(\n",
      "        user_profile=json.dumps(user_profile, ensure_ascii=False),\n",
      "    ...<2 lines>...\n",
      "        weather=json.dumps(weather, ensure_ascii=False),\n",
      "    )\n",
      "KeyError: '\\n  \"summary\"'\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio, threading, uvicorn\n",
    "nest_asyncio.apply()\n",
    "\n",
    "PORT = 8020\n",
    "config = uvicorn.Config(app, host=\"127.0.0.1\", port=8023, log_level=\"info\")\n",
    "server = uvicorn.Server(config)\n",
    "\n",
    "t = threading.Thread(target=server.run, daemon=True)\n",
    "t.start()\n",
    "print(f\"ğŸš€ Uvicorn at http://127.0.0.1:{PORT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7dd5b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROOT /] 200 | application/json | 64 bytes\n",
      "{\"ok\":true,\"model\":\"gemini-1.5-flash\",\"places_provider\":\"kakao\"}\n",
      "------------------------------------------------------------\n",
      "[SELFTEST /selftest/gemini] 200 | application/json | 59 bytes\n",
      "{\"ok\":true,\"model\":\"gemini-1.5-flash\",\"sample\":{\"ok\":true}}\n",
      "------------------------------------------------------------\n",
      "[RECO DEBUG /recommend?debug=true] 200 | application/json | 165 bytes\n",
      "{\"summary\":\"debug bypass\",\"recommendations\":[],\"missions\":[],\"_debug\":{\"candidates_len\":30,\"weather\":{\"when\":\"now\",\"status\":\"clear\",\"temp_c\":29.01,\"rain_prob\":0.1}}}\n",
      "------------------------------------------------------------\n",
      "[RECO FULL /recommend] 500 | application/json | 2240 bytes\n",
      "{\"type\":\"server_exception\",\"detail\":\"'\\\\n  \\\"summary\\\"'\",\"trace\":\"Traceback (most recent call last):\\n  File \\\"c:\\\\Users\\\\sj021\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\starlette\\\\middleware\\\\errors.py\\\", line 164, in __call__\\n    await self.app(scope, receive, _send)\\n  Fi ...[truncated]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "BASE = \"http://127.0.0.1:8023\"\n",
    "\n",
    "def brief(r, name):\n",
    "    print(f\"[{name}] {r.status_code} | {r.headers.get('content-type')} | {len(r.content)} bytes\")\n",
    "    print(r.text[:300] + (\" ...[truncated]\" if len(r.text)>300 else \"\"))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "# 5-1) ë£¨íŠ¸\n",
    "r = requests.get(f\"{BASE}/\", timeout=10)\n",
    "brief(r, \"ROOT /\")\n",
    "\n",
    "# 5-2) Gemini ì…€í”„í…ŒìŠ¤íŠ¸\n",
    "r = requests.get(f\"{BASE}/selftest/gemini\", timeout=30)\n",
    "brief(r, \"SELFTEST /selftest/gemini\")\n",
    "\n",
    "# 5-3) /recommend (LLM ìš°íšŒ)\n",
    "payload = {\n",
    "    \"user_profile\": {\"budget_level\": 2, \"tags\": [\"ì¡°ìš©\",\"ì½˜ì„¼íŠ¸\"], \"allergies\": [\"ê²¬ê³¼\"]},\n",
    "    \"context\": {\n",
    "        \"lat\": 36.6424, \"lng\": 127.4887, \"category\": \"cafe\",\n",
    "        \"radius_m\": 1500, \"when\": \"today_evening\",\n",
    "        \"party\": \"solo\", \"intent\": \"study\", \"open_now\": True\n",
    "    }\n",
    "}\n",
    "r = requests.post(f\"{BASE}/recommend?debug=true\", json=payload, timeout=60)\n",
    "brief(r, \"RECO DEBUG /recommend?debug=true\")\n",
    "\n",
    "# 5-4) /recommend (ì •ìƒ ê²½ë¡œ: Gemini í¬í•¨)\n",
    "r = requests.post(f\"{BASE}/recommend\", json=payload, timeout=120)\n",
    "brief(r, \"RECO FULL /recommend\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6281d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
